{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c84d17-c01b-4515-be6b-8c264683c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file is to compare speed ups and how to use numba and cp \n",
    "\n",
    "from numba import njit\n",
    "import numpy as np \n",
    "import cupy as cp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65707a03-645d-45d4-8aef-0c6dbb17d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Just apply the @njit decorator to python functions that use simple python packages to improve speed up \n",
    "@njit\n",
    "def monte_carlo_pi_numba(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = np.random.random()\n",
    "        y = np.random.random()\n",
    "        if (x ** 2 + y ** 2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples\n",
    "\n",
    "def monte_carlo_pi(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = np.random.random()\n",
    "        y = np.random.random()\n",
    "        if (x ** 2 + y ** 2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd7caf4-1595-4446-8fbe-190e53f9d2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655 μs ± 2.74 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "monte_carlo_pi(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f11e7c-9ae4-4b1b-88b6-736452d1f430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.43 μs ± 987 ns per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "monte_carlo_pi_numba(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325609f3-b788-4fa7-b752-c812298f53c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The njit improved speedup by 99% and used as much if not less memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46962ade-8c2d-4cdd-98b7-6bd633e3e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are memory pools used to see stats of GPU memory \n",
    "mempool = cp.get_default_memory_pool()\n",
    "pinned_mempool = cp.get_default_pinned_memory_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eacd3f0-dd2e-471b-91b2-590becc4370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Create an array on CPU.\n",
    "# np allocates 40000 bytes in CPU (not managed by cp memory pool).\n",
    "a_cpu = np.ndarray(shape=(100,100), dtype=np.float32)\n",
    "print(a_cpu.nbytes)                      # 40000\n",
    "\n",
    "# You can access statistics of these memory pools.\n",
    "print(mempool.used_bytes())              # 0\n",
    "print(mempool.total_bytes())             # 0\n",
    "print(pinned_mempool.n_free_blocks())    # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6bdc97-af19-4caa-98cb-1c3b0c7bd016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "40448\n",
      "40448\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cupy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Transfer the array from CPU to GPU. Note that this takes time. \n",
    "# This allocates 400 bytes from the device memory pool, and another 400\n",
    "# bytes from the pinned memory pool.  The allocated pinned memory will be\n",
    "# released just after the transfer is complete.  Note that the actual\n",
    "# allocation size may be rounded to larger value than the requested size\n",
    "# for performance.\n",
    "a = cp.array(a_cpu)\n",
    "print(a.nbytes)                          # 400\n",
    "print(mempool.used_bytes())              # 512\n",
    "print(mempool.total_bytes())             # 512\n",
    "print(pinned_mempool.n_free_blocks())    # 1\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d83393b-c420-4daf-9cc1-824f1b906ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "40448\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# When the array goes out of scope, the allocated device memory is released\n",
    "# and kept in the pool for future reuse.\n",
    "a = None  # (or `del a`)\n",
    "print(mempool.used_bytes())              # 0\n",
    "print(mempool.total_bytes())             # 512\n",
    "print(pinned_mempool.n_free_blocks())    # 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a7059b5-ccde-48ed-9f0b-a77f7029a663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You can clear the memory pool by calling `free_all_blocks`.\n",
    "mempool.free_all_blocks()\n",
    "pinned_mempool.free_all_blocks()\n",
    "print(mempool.used_bytes())              # 0\n",
    "print(mempool.total_bytes())             # 0\n",
    "print(pinned_mempool.n_free_blocks())    # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4927239-b891-461c-947a-c8917a2a3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets test the effeciency of GPU blocks \n",
    "from scipy import fft \n",
    "\n",
    "a_cpu = np.random.randint(0, 255, size=(1000,1000))\n",
    "a_gpu = cp.array(a_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20ff928-69b0-4d8e-803b-7093936f3f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.5 ms ± 1.43 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "fft.fftn(a_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e9d5a4-b156-4697-b098-96205f9e60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You have to import custom cupy functions that resemble the same functions in scipy to apply on the cupy arrays\n",
    "from cupyx.scipy import fft as fft_gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a085e51-f4de-4798-bf49-011e6599544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.86 ms ± 22.2 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "fft_gpu.fftn(a_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2b00003-9932-4dfd-8e4f-6acd92cc1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One thing to note is that the bigger the tensor, the bigger the difference in speed between gpu and cpu compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5449c337-d3c4-4dae-a993-cdbdfd885cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This shows that the tensors are very similar to each other \n",
    "fft_cpu = fft.fftn(a_cpu)\n",
    "fft_sent_back = cp.asnumpy(fft_gpu.fftn(a_gpu))\n",
    "np.allclose(fft_cpu, fft_sent_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c917aab-1de9-445e-bce7-b6b31b03e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suggest watching https://www.youtube.com/watch?v=9bBsvpg-Xlk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db665d2c-da38-43b5-a4bb-c494489ff4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce RTX 4060'                              [SUPPORTED]\n",
      "                      Compute Capability: 8.9\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 1\n",
      "                                    UUID: GPU-01a4cc78-4e20-c926-c2c8-2fdf09d794ab\n",
      "                                Watchdog: Enabled\n",
      "                            Compute Mode: WDDM\n",
      "             FP32/FP64 Performance Ratio: 64\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function uses a cuda just in time decorator to increment all values in a given matrix by 1 \n",
    "from numba import cuda\n",
    "\n",
    "cuda.detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fe661d7-a018-4fdf-9869-efdeb6041739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numba.cuda.cudadrv.devicearray.DeviceNDArray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_cpu = np.random.randint(0, 10, size=(2000, 2000))\n",
    "\n",
    "#Add numpy array to gpu via cuda instead of cupy \n",
    "a_cuda = cuda.to_device(a_cpu)\n",
    "type(a_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "526f89f0-00e9-412e-a051-4dddef987f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cupy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adds a cupy array wrapper to cuda object (Numba works with cupy arrays as well)\n",
    "a_gpu = cp.asarray(a_cuda)\n",
    "type(a_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd2d906c-f4fc-478d-8779-50e9cb1d83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive cuda implementation of matrix multiplication \n",
    "@cuda.jit\n",
    "def matmul_1(A, B, C):\n",
    "    #C = AB\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]: \n",
    "        tmp = 0 \n",
    "    for k in range(A.shape[1]):\n",
    "        tmp += A[i, k] *B[k, j]\n",
    "    C[i,j] = tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f1479fe7-110a-4d6d-89ed-7fbcc958d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.random.seed(1)\n",
    "SIZE = (3, 3)\n",
    "A = np.random.uniform(1, 10, size=SIZE)\n",
    "B = np.random.uniform(1, 10, size=SIZE)\n",
    "\n",
    "A_gpu = cp.asarray(A)\n",
    "B_gpu = cp.asarray(B)\n",
    "C_gpu = cp.zeros(SIZE, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eccdd2f5-abc1-4eee-bb45-0b9f0b251e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks in grid (1, 1)\n",
      "Matrix multiplication works for 16 by 16\n"
     ]
    }
   ],
   "source": [
    "threadsperblock = (16, 16) \n",
    "blockspergrid_x = int(np.ceil(C.shape[0]/threadsperblock[0]))\n",
    "blockspergrid_y = int(np.ceil(C.shape[1]/threadsperblock[1]))\n",
    "blockspergrid = (blockspergrid_x , blockspergrid_y)\n",
    "print(f\"blocks in grid {blockspergrid}\")\n",
    "print(f\"Matrix multiplication works for {threadsperblock[0]*blockspergrid_x} by {threadsperblock[1]*blockspergrid_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "370c80db-9ec7-42f8-8760-fa481a3465ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JJOBY\\anaconda3\\envs\\GYM\\lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#excute cuda kernel function \n",
    "matmul_1[blockspergrid, threadsperblock](A, B, C_gpu)\n",
    "C = np.dot(A, B)\n",
    "np.allclose(C, C_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dcdadf2e-4b04-45d5-a2e7-7a5b5ff067fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, cupy.ndarray)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(C), type(C_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae74b4ee-e238-4ac7-82bc-ebb5659b0941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59.92982297, 111.8885066 ,  75.98230458],\n",
       "       [ 54.83285418,  81.38135179,  79.5280989 ],\n",
       "       [ 46.20612758,  68.34816442,  71.49490658]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "20d87ef2-e69a-45be-8111-4be49372dd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59.92982297, 111.8885066 ,  75.98230458],\n",
       "       [ 28.28848932,  81.38135179,  79.5280989 ],\n",
       "       [ 17.50708962,  68.34816442,  14.63911448]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afa033-49c6-4c76-be1c-dfbca1e4d567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24656e-9a3f-4bab-a244-8bf8a2cb4050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2dd2f-f156-4d30-b9c3-f24d6b3b700b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
